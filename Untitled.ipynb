{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f415f611-b4b3-4655-a7fe-89a34990ded3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading data and feature engineering...\n",
      "Step 2: Creating positive and negative samples for training...\n",
      "Step 3: Merging features for training and test data...\n",
      "Step 4: Training the model...\n",
      "Step 5: Generating submission file...\n",
      "\n",
      "Assignment complete! The submission.csv file has been created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# --- Step 1: Data Loading and Initial Feature Engineering ---\n",
    "\n",
    "print(\"Step 1: Loading data and feature engineering...\")\n",
    "\n",
    "try:\n",
    "    orders = pd.read_csv('orders.csv', low_memory=False)\n",
    "    vendors = pd.read_csv('vendors.csv')\n",
    "    train_locations = pd.read_csv('train_locations.csv')\n",
    "    test_locations = pd.read_csv('test_locations.csv')\n",
    "    sample_submission = pd.read_csv('SampleSubmission.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nError: {e}. Please ensure all CSV files are in the same directory as this notebook.\")\n",
    "    raise\n",
    "\n",
    "# --- Create a Haversine distance function ---\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    if pd.isnull(lat1) or pd.isnull(lon1) or pd.isnull(lat2) or pd.isnull(lon2):\n",
    "        return np.nan\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# --- Step 2: Create a balanced training dataset with positive and negative samples ---\n",
    "\n",
    "print(\"Step 2: Creating positive and negative samples for training...\")\n",
    "\n",
    "# Merge orders with train_locations to get the location_number\n",
    "\n",
    "orders = orders.merge(train_locations, on=['customer_id'], how='left', suffixes=('_orders', '_loc'))\n",
    "orders.dropna(subset=['location_number'], inplace=True)\n",
    "orders['location_number'] = orders['location_number'].astype(int)\n",
    "\n",
    "# 1. Positive Samples (Actual Orders)\n",
    "\n",
    "orders['target'] = 1\n",
    "positive_samples = orders[['customer_id', 'vendor_id', 'location_number', 'target']].copy()\n",
    "\n",
    "# 2. Negative Samples (Non-Orders)\n",
    "\n",
    "np.random.seed(42)\n",
    "unique_customers = orders['customer_id'].unique()\n",
    "\n",
    "# Corrected line: Rename the 'id' column to 'vendor_id'\n",
    "\n",
    "vendors.rename(columns={'id': 'vendor_id'}, inplace=True)\n",
    "unique_vendors = vendors['vendor_id'].unique()\n",
    "existing_pairs = set(tuple(row) for row in positive_samples[['customer_id', 'vendor_id']].values)\n",
    "negative_samples_list = []\n",
    "negative_samples_count = len(positive_samples)\n",
    "\n",
    "while len(negative_samples_list) < negative_samples_count:\n",
    "    customer_id = np.random.choice(unique_customers)\n",
    "    vendor_id = np.random.choice(unique_vendors)\n",
    "    if (customer_id, vendor_id) not in existing_pairs:\n",
    "        negative_samples_list.append({'customer_id': customer_id, 'vendor_id': vendor_id, 'location_number': 0, 'target': 0})\n",
    "\n",
    "negative_samples = pd.DataFrame(negative_samples_list)\n",
    "training_data = pd.concat([positive_samples, negative_samples], ignore_index=True)\n",
    "\n",
    "\n",
    "# --- Step 3: Feature Engineering for Training and Test Data ---\n",
    "print(\"Step 3: Merging features for training and test data...\")\n",
    "\n",
    "# Merge with vendor features\n",
    "training_data = training_data.merge(vendors, on='vendor_id', how='left')\n",
    "# Merge with location features\n",
    "training_data = training_data.merge(train_locations, on=['customer_id', 'location_number'], how='left', suffixes=('_vendor', '_cust'))\n",
    "\n",
    "# Prepare the test data from the SampleSubmission file\n",
    "test_df = sample_submission.copy()\n",
    "test_df[['customer_id', 'location_number', 'vendor_id']] = test_df['CID X LOC_NUM X VENDOR'].str.split(' X ', expand=True)\n",
    "test_df['location_number'] = pd.to_numeric(test_df['location_number'])\n",
    "test_df['vendor_id'] = pd.to_numeric(test_df['vendor_id'])\n",
    "\n",
    "# Merge with vendor features\n",
    "\n",
    "\n",
    "test_df = test_df.merge(vendors, on='vendor_id', how='left')\n",
    "\n",
    "# Merge with location features (using test_locations)\n",
    "\n",
    "test_df = test_df.merge(test_locations, on=['customer_id', 'location_number'], how='left', suffixes=('_vendor', '_cust'))\n",
    "\n",
    "\n",
    "# Calculate distance for both sets\n",
    "\n",
    "training_data['distance_km'] = training_data.apply(\n",
    "    lambda row: haversine_distance(row['latitude_cust'], row['longitude_cust'], row['latitude_vendor'], row['longitude_vendor']), axis=1\n",
    ")\n",
    "test_df['distance_km'] = test_df.apply(\n",
    "    lambda row: haversine_distance(row['latitude_cust'], row['longitude_cust'], row['latitude_vendor'], row['longitude_vendor']), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# --- Step 4: Train the Final Model ---\n",
    "\n",
    "print(\"Step 4: Training the model...\")\n",
    "\n",
    "features = ['distance_km', 'delivery_charge', 'serving_distance', 'is_open',\n",
    "            'commission', 'discount_percentage', 'vendor_rating', 'prepration_time',\n",
    "            'rank', 'one_click_vendor', 'country_id', 'city_id', 'vendor_category_id']\n",
    "\n",
    "# Create the training and testing sets #\n",
    "\n",
    "X_train = training_data[features]\n",
    "y_train = training_data['target']\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Impute missing values with the mean\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Train the RandomForestClassifier model\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# --- Step 5: Make Predictions and Create Submission File ---\n",
    "\n",
    "print(\"Step 5: Generating submission file...\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "\n",
    "test_df['target'] = model.predict(X_test_imputed)\n",
    "\n",
    "# Prepare the final submission file in the required format\n",
    "\n",
    "submission = test_df[['CID X LOC_NUM X VENDOR', 'target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"\\nAssignment complete! The submission.csv file has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd80c40-a956-4aff-9ad4-2531726bca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and imputer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Make sure the 'model' and 'imputer' variables exist in your session\n",
    "# (If you restarted the notebook, you need to run the full code again)\n",
    "\n",
    "try:\n",
    "    joblib.dump(model, 'recommender_model.joblib')\n",
    "    joblib.dump(imputer, 'imputer.joblib')\n",
    "    print(\"Model and imputer saved successfully!\")\n",
    "except NameError:\n",
    "    print(\"Error: 'model' or 'imputer' not found. Please run the full project code from start to finish first.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff8a9e-838e-46ec-a044-54e96461e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
